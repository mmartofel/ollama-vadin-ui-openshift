kind: Deployment
apiVersion: apps/v1
metadata:
  name: ollama-client
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama-client
  template:
    metadata:
      labels:
        app: ollama-client
    spec:
      containers:
        - name: container
          image: quay.io/mmartofe/ollama-vaadin-gui
          ports:
            - containerPort: 8080
              protocol: TCP
          env:
            - name: MODEL
              valueFrom:
                configMapKeyRef:
                  name: ollama-client-configmap
                  key: MODEL
            - name: AI_OLLAMA_BASE_URL
              valueFrom:
                configMapKeyRef:
                  name: ollama-client-configmap
                  key: AI_OLLAMA_BASE_URL
            - name: PORT
              valueFrom:
                configMapKeyRef:
                  name: ollama-client-configmap
                  key: PORT
            - name: TEMPERATURE
              valueFrom:
                configMapKeyRef:
                  name: ollama-client-configmap
                  key: TEMPERATURE
            - name: LOG_LEVEL
              valueFrom:
                configMapKeyRef:
                  name: ollama-client-configmap
                  key: LOG_LEVEL
          resources:
            limits:
              cpu: '1'
              memory: 1Gi
            requests:
              cpu: '0.3'
              memory: 500Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          imagePullPolicy: Always
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      dnsPolicy: ClusterFirst
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 25%
      maxSurge: 25%
  revisionHistoryLimit: 10
  progressDeadlineSeconds: 600