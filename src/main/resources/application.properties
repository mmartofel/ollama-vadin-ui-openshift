server.port = ${PORT:8080}
server.shutdown = graceful
server.address=0.0.0.0

spring.application.name = developer-assistance
spring.mustache.check-template-location = false
spring.threads.virtual.enabled = true

# This line is to connect your container running on podman once your Ollama server is working at your pc locally
# spring.ai.ollama.base-url = ${AI_OLLAMA_BASE_URL:http://host.containers.internal:11434}

spring.ai.ollama.base-url = ${AI_OLLAMA_BASE_URL:http://10.88.0.11:11434}
spring.ai.ollama.chat.options.model=${MODEL:mistral}
spring.ai.ollama.chat.options.temperature=${TEMPERATURE:0.7}
logging.level.org.atmosphere = ${LOG_LEVEL:warn}

# Launch the default browser when starting the application in development mode
vaadin.launch-browser = false